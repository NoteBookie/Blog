---
layout: page
title: JOSLab4：Preemptive Multitasking
categories:
    - note
---

JOS在Lab4以前只支持单核的架构，Lab4的partA带来一个重大改变，即SMP，意味着JOS从此支持多核架构。

### Part A: Multiprocessor Support and Cooperative Multitasking

在partA里需要完成的工作是实现多核的支持、用户态的进程调度和fork系统调用。具体来说包括有：
* 初始化多核的数据结构
* 对于多核共享的数据，处理data race
* yield的系统调用实现
* fork的系统调用实现

### Exercise 1

#### excited

1. SMP: JOS支持的多核架构是SMP（symmetric multiprocessing），这意味着多个核在访问系统资源是互相平等的关系，彼此之间通过总线交互。也有与之对应的AMP（Asymmetric multiprocessing），其每个核的职责是不对称的。SMP中，核被分为1个BSP和多个AP，由硬件决定谁是BSP。（例如Qemu总是把CPU0视作BSP）
2. BSP：bootstrap processor。负责初始化整个系统和OS的一些基本数据结构，比如pages。
3. AP：application processor。由BSP发送中断（STARTUP）被激活。
4. LAPIC：每一个核都有一个LAPIC，这个单元有两个作用：
	* 区别每个CPU，LAPIC提供对应的CPU一个唯一的ID。可以通过LAPIC得知进程使用的是哪个核。
	* 接受中断并发送给CPU的逻辑核心
5. MMIO：每个核都通过MMIO实现LAPIC，其将物理地址映射到IO设备寄存器，其后只需要通过对物理地址的load/store就可以访问IO设备。

#### exercise

根据文档提示，JOS会用到MPENTRY_PADDR这一位置的page来访问AP boot时的代码，所以需要在page_init()时，将这一位置标记为已用：

~~~c
	for (i = 0; i < npages; i++) {
		if(i == PGNUM(MPENTRY_PADDR) || i == 0  || (i >= PGNUM(IOPHYSMEM) 
				&& (i <= PGNUM(PADDR(boot_alloc(0)))))) {
			pages[i].pp_ref = 1;
			pages[i].pp_link = NULL;
			continue;
		}
	//...
~~~

#### question1

由于程序是在runtime时才进行AP boot，这个时候使用的已经是虚拟地址了，所以之前所假设的link address是错误的，为了摒弃错误的假设并且获得确切的物理地址，就用这个MPBOOTPHYS这个宏把虚拟地址转化到MPENTRY_PADDR的物理地址上。

### Exercise 2 & 3
#### excited

AP boot的过程：

1. BSP通过mpconfig.c中的mp_init()读取CPU个数等系统信息，随后根据这些信息，初始化自己APIC对应的MMIO（lapic_init()）。
2. BSP初始化中断控制器，在pic_init()中。
3. 将汇编代码mpentry.S装载到MPENTRY_ADDR的内存中，BSP通过发送中断让每个AP都执行这段代码。
4. 在mpentry.S的最后，控制流跳到mp_main中，进行每个AP的boot：
	* 切换页表到kern_pgdir
	* 初始化自己的APIC
	* 初始化自己的GDT和段寄存器
	* 初始化自己的TSS和IDT （trap_init_percpu）

文档提示我去看cpu.h中CPU的数据结构，其大致如下：

~~~c
struct Cpu {
	uint8_t cpu_id;                 // Local APIC ID; index into cpus[] below
	volatile unsigned cpu_status;   // The status of the CPU
	struct Env *cpu_env;            // The currently-running environment.
	struct Taskstate cpu_ts;        // Used by x86 to find stack for interrupt
};
~~~	

#### exercise 2

memlayout.h中更新了STACK的描述，我以此为依据完成ex2，BSP在mem_init()时初始化所有CPU的栈的页表：

~~~c
	for (i = 0 ;i < NCPU ;i ++){
		kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP);
		boot_map_region(kern_pgdir, kstacktop_i - KSTKSIZE, KSTKSIZE, 
		    	PADDR(percpu_kstacks[i]), PTE_W | PTE_P);
	}
~~~	

#### exercise 3

在BSP和AP boot到trap_init()时，它们都需要初始化自己的TSS和IDT：

~~~c
void
trap_init_percpu(void)
{	
	struct Taskstate * ts_percpu = &thiscpu->cpu_ts;
	int i = thiscpu->cpu_id;

	//init for sysenter
	extern void sysenter_handler();
	wrmsr(0x174, GD_KT, 0);
	wrmsr(0x175, KSTACKTOP - i * (KSTKSIZE + KSTKGAP), 0);
	wrmsr(0x176, (uint32_t)(char *) sysenter_handler, 0); 

	// Setup a TSS so that we get the right stack
	// when we trap to the kernel.
	ts_percpu->ts_esp0 = KSTACKTOP - i * (KSTKSIZE + KSTKGAP);
	ts_percpu->ts_ss0 = GD_KD;

	// Initialize the TSS slot of the gdt.
	gdt[(GD_TSS0 >> 3) + i] = SEG16(STS_T32A, (uint32_t) (ts_percpu),
					sizeof(struct Taskstate), 0);
	gdt[(GD_TSS0 >> 3) + i].sd_s = 0;

	// Load the TSS selector (like other segment selectors, the
	// bottom three bits are special; we leave them 0)
	ltr(GD_TSS0 + (i << 3));

	// Load the IDT
	lidt(&idt_pd);
}
~~~

对于每个CPU i来说，它的TSS是cpus[i].cpu_ts，它对应的TSS描述符是GDT中的gdt[(GD_TSS0 >> 3) + i]。

运行`make qemu CPUS=4`后可以看到和文档描述一样的输出。

### exercise 4 & 4.1

#### excited

多核架构下，存在CPU访问同一段程序的竞争问题。JOS为了解决这个问题，提供了一把内核大锁(Big Kernel Lock)，其使得每时每刻都只有一个env在kernel态里运行，粗糙的防止了多个CPU同时修改一个env的竞争。

* 需要在这些场合拿/放锁：
	*  i386_init()，在叫醒其余CPU前。这是为了防止它们在还没初始化完前就拿到锁，使得初始化无法继续。
	*  mp_main()，在跑起AP上的env前给它上锁。
	*  trap()，从用户态到了内核态。
	*  env_run()，跳转到用户态时需要放锁（在env_pop_tf前）。
	*  特殊的：因为Lab3里允许了sysenter进入syscall，所以，尽管Lab4中的syscall是通过trap完成的，我们还是要在sysenter进入到syscall的过程中加锁。

#### exercise 4.1

这个exercise的要求是实现spinlock，	IBM上有一篇很切合的[文档](http://www.ibm.com/ "文档")帮助了我理解spinlock的含义。

holding中使用own和next是否相等来判断是否拿锁：

~~~c
	return lock->own != lock->next && lock->cpu == thiscpu;
~~~		

spin_lock中包含“拿票据”和“等待到号”两个部分，首先是增加next并且得到增加前的返回值作为票据，然后不断自旋判断own为票号为止。

~~~c
	int own = atomic_return_and_add(&lk->next, 1);
	while(atomic_return_and_add(&lk->own, 0)!= own);
	asm volatile("pause");
~~~

放锁只需要将own加1即可，持有下一个票号的CPU会自行拿到锁。

更换define后运行`make qemu CPUS=4`，可以看到四个CPU的spinlock_test()都获得了通过。不过由于partC中的测试对时间要求很严格，而spinlock本身因为自旋会比较慢，所以我是用的给定的DEBUG_SPINLOCK过的测试。如果想要验证这个部分的正确性，就在头文件中使用`#define USE_TICKET_SPIN_LOCK`即可。

#### question 2

所有CPU分享同一个栈是显然不可能的。举例来说，CPU0 push， CPU1 push，随后CPU0 pop就会得到错误的数据，尽管这一切都是顺序的、原子的（相对来说）操作。

### Exercise 5
#### excited

Round-Robin Scheduling：
* 完成sched_yield()函数以启动第一个用户态程序
* 所有进程按照envs数组中的顺序调度，当前进程yield后就从当前进程在数组中的位置开始向后搜索可以调度的进程，搜到末尾后就从头开始。
* 一个小优化：如果env[i].env_id已经为0，证明程序进入了未被分配的env区域中，所以可以直接从env[0]开始遍历。（但是对最后的ipc优化并不大，并且有“env可能是只是被free掉的隐忧”）
* sysenter指令会引起麻烦的连锁反应：
	* 用户通过sysenter进度sys_yield，但是调度需要用到Trapframe，所以在sysenter_handler开头压入通用寄存器和EFLAGS来构建。
	* sysenter和sysexit指令会屏蔽中断，所以需要sti来手动开启。

#### exercise
kern/sched.c。通过`%NENV`来让i自然从尾部移动到头部。
~~~c
	uint32_t env_id;
	if(curenv != NULL){
		env_id = ENVX(curenv->env_id);
		for(i = (env_id+1)%NENV; i != env_id; ){
			if(envs[i].env_id == 0){	//小优化
				i = 0;
				continue;
			}
			if(envs[i].env_status == ENV_RUNNABLE &&
				envs[i].env_type != ENV_TYPE_IDLE){
				env_run(&envs[i]);
			}
			i = (i+1)%NENV;
		}
		if(curenv->env_status == ENV_RUNNING){
			env_run(curenv);
		}
	}
~~~

#### excited

文档中曾说明：如果完成了这一部分，那么JOS应该可以通过`make run-yield`的测试。然而我在实际编码过程中，却反反复复的出现general protection。这个问题困扰了我两天的时间，最后终于在学长的提示下lapic_init中找到了答案，此函数会被所有CPU调用，我在这里就着代码简要分析一下它的工作流程：

~~~c
void
lapic_init(void)
{
	if (!lapic) 
		return;

	// 通过设置SVR，启用LAPIC。所有的AP都需要手动启用。
	lapicw(SVR, ENABLE | (IRQ_OFFSET + IRQ_SPURIOUS));

	// 这三句设置了Apic Timer，参数PERIODIC表示TCCR从TICR开始减少，
	// 减少到零九引发一个中断，随后重设。TDCR设置为X1表示每个时钟周期
	// Count会减1.
	lapicw(TDCR, X1);
	lapicw(TIMER, PERIODIC | (IRQ_OFFSET + IRQ_TIMER));
	lapicw(TICR, 10000000); 

	// 随后的代码禁止了LAPIC发送其他中断的功能，通过这个函数，LAPIC在
	// 内部发生错误（时钟中断）时会以我们设置好的中断向量向CPU发中断
}
~~~

正是由于在这个函数，我需要在trap中提前设置好TIMER的调用门，尽管时钟中断是partC抢占式调度才会用到的内容。不然的话，周期性的时钟中断就会触发general protection，因为JOS没有提供TIMER的handler。（奇怪的是，问遍周围的小伙伴却都没有碰到这个情况…）

~~~c
SETGATE(idt[IRQ_OFFSET + IRQ_TIMER], 0, GD_KT, entry20, 0);
~~~

#### question 3

所有的用户态程序共享相同的UENVS的地址空间，而envs数组就存于其上。所以更换为另一个被调度的env的pgdir也是依然可以访问的。

### Exercise 6

这个练习需要我完成fork的系统调用，主要难度在于小心翼翼的处理各种corner case，把参数的判断做好，很麻烦。在这里的sys_exofork是通过TRAP的形式传递的（你说折腾不），所以要再写一个SYSCALL的handler，在trapframe里保存好syscall需要的各个寄存器值，然后在trap()里跳转到syscall里去。

#### exercise

##### sys_exofork

这个函数的作用是alloc出一个新的env，同时用父进程的寄存器初始化子进程的寄存器，之所以把子进程设置为NOT RUNNABLE的原因是因为还没有给子进程初始化页表/分配物理页。Fork系统调用对于父进程返回子进程的ID，对于子进程返回0，实现的办法就是`child->env_tf.tf_regs.reg_eax = 0;`这一句，因为syscall的返回值是放在trapframe的eax上的，所以初始化成0即可。

~~~c
	struct Env *child;
	int r;

	if ((r = env_alloc(&child, curenv->env_id)) < 0)
		return r;
	child->env_status = ENV_NOT_RUNNABLE;
	child->env_tf = curenv->env_tf;
	child->env_tf.tf_regs.reg_eax = 0;
	return child->env_id;
~~~

##### sys_env_set_status

这个函数修改子进程的状态。之所以不和sys_exofork放在一个函数里，是为了不重复实现功能，把函数的粒度降到合适的地步。这里要注意一些检查：
* envid2env: 检查envid是不是存在以及调用者是否有权限
* env_status: 检查env是不是在合法的状态下

~~~c
	struct Env *e;
	int r;

	if ((r = envid2env(envid, &e, 1)) < 0)
		return r;
	if (e->env_status != ENV_RUNNABLE && e->env_status != ENV_NOT_RUNNABLE)
		return -E_INVAL;
	e->env_status = status;
	return 0;
~~~

##### sys_page_alloc

这个函数的作用是初始化一个权限为perm的page，并且映射到va这个虚拟地址上。需要注意以下几点：
* perm必须参照PTE_SYSCALL规定的权限
* va不能超过UTOP，而且必须对齐PGSIZE，这是为了检查user是否可以访问对应的虚拟空间（下不再提）
* envid必须存在。凡是出现envid，都需要验证有效性（下不再表）
* 物理页如果alloc失败，要报错
* pte如果insert失败，要把物理页回收

~~~c
	struct Env *e;
	struct Page *p;
	int r;

	if (!(perm & PTE_P) || !(perm & PTE_U) || (perm & (~PTE_SYSCALL)) != 0)
		return -E_INVAL;
	if (((uint32_t)va) >= UTOP || ((uint32_t)va) % PGSIZE != 0)
		return -E_INVAL;
	if ((r = envid2env(envid, &e, 1)) < 0)
		return -E_BAD_ENV;

	p = page_alloc(ALLOC_ZERO);
	if (!p)
		return -E_NO_MEM;
	if ((r = page_insert(e->env_pgdir, p, va, perm)) < 0) {
		page_free(p);
		return -E_NO_MEM;
	}
	return 0;
~~~

##### sys_page_map

这个函数的作用是把srcenvid对应的srcva的页复制到dst对用的dstva中，并且更新权限perm。

~~~c
	struct Env *srce, *dste;
	struct Page *p;
	pte_t *pte;
	int r;

	if (((uint32_t)srcva) >= UTOP || ((uint32_t)srcva) % PGSIZE != 0)
		return -E_INVAL;
	if (((uint32_t)dstva) >= UTOP || ((uint32_t)dstva) % PGSIZE != 0)
		return -E_INVAL;
	if ((r = envid2env(srcenvid, &srce, 1)) < 0)
		return -E_BAD_ENV;
	if ((r = envid2env(dstenvid, &dste, 1)) < 0)
		return -E_BAD_ENV;

	if(!(p = page_lookup(srce->env_pgdir, srcva, &pte)))
		return -E_INVAL;
	if (!(perm & PTE_P))
		return -E_INVAL;
	if (!(*pte & PTE_W) && (perm & PTE_W))
		return -E_INVAL;

	if ((r = page_insert(dste->env_pgdir, p, dstva, perm)) < 0)
		return -E_NO_MEM;
	return 0;
~~~

##### sys_page_unmap

这个函数的作用是释放envid所对应的va。

~~~c
	struct Env *e;
	int r;

	if ((r = envid2env(envid, &e, 1)) < 0)
		return -E_BAD_ENV;

	if (((uint32_t)va) >= UTOP || ((uint32_t)va) % PGSIZE != 0)
		return -E_INVAL;
	
	page_remove(e->env_pgdir, va);
	return 0;
~~~

##### fork

在syscall的switch写好各项分支，运行make grade可以看到得到了5分（不容易，四天没有了…），不过再看一下dumbfork的实现吧——尽管接下来要做的COW的fork完全不一样。这里的fork完全通过系统调用在kernel实现，关键的函数就是duppage：

~~~c
void
duppage(envid_t dstenv, void *addr)
{
	int r;

	// This is NOT what you should do in your fork.
	if ((r = sys_page_alloc(dstenv, addr, PTE_P|PTE_U|PTE_W)) < 0)
		panic("sys_page_alloc: %e", r);
	if ((r = sys_page_map(dstenv, addr, 0, UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
		panic("sys_page_map: %e", r);
	memmove(UTEMP, addr, PGSIZE);
	if ((r = sys_page_unmap(0, UTEMP)) < 0)
		panic("sys_page_unmap: %e", r);
}
~~~

分析下这个函数执行的过程：
* Parent通过sys_page_alloc给Son分配一个虚拟地址va和一个对应的物理页。
* 让Son把自己的va映射到UTEMP段，此时UTEMP段同时被Son va 和 Parent 映射
* 把addr里的东西（UTEXT段的一部分）复制到UTEMP上，通过memmove。
* Parent解除映射自己的UTEMP，这样UTEMP就只被Son映射了。

从这个函数可以看出，JOS之前把fork拆成这么多小粒度的函数是很有作用的，因为诸如map/unmap的操作可能被很多的用户程序用到，是更有效的单元。

### Part B：Copy-on-Write Fork

这一个部分的目的是实现一个COW的fork。之所以要这样做呢，是因为在实际运用中有很多子进程被fork出来后，立刻就执行了exec，完全没有用到从父进程那里继承过来的资源，如果每次fork都完整的复制整个父进程，会是对系统资源的浪费。而COW，就意味着当子进程使用到父进程的资源时，系统再把那些页复制出来，所谓写时拷贝。

COW-fork把Son和Parent的va都映射到一个pa上，并且把pa的perm改为Read Only，这样在写的时候就会触发PGFLT，可以在trap后新建一个物理页。

我的fork将作为用户态的调用，内核态保留的是我在PartA里写好的一些服务。实现这样的fork的过程如下：
* 实现一个系统调用：其允许用户程序注册一个handler函数
* 实现用户态的PGFLT的handler：用户态的PGFLT handler会运行在用户异常栈上，我需要让这个handler返回到发生PGFLT的位置
* 实现用户态下COW的fork：一旦发生PGFLT，可以通过上文中的handler把COW的页复制到新的物理页上，并且设置权限。

### Exercise 7

实现sys_env_set_pgfault_upcall，这个系统调用可以注册func为env的pgfault_upcall. kernel通过修改 user env 的栈和寄存器来实现返回user态时，运行upcall函数。

~~~c
static int
sys_env_set_pgfault_upcall(envid_t envid, void *func)
{
	struct Env *e;
	int r;

	if ((r = envid2env(envid, &e, 1)) < 0)
		return -E_BAD_ENV;
	e->env_pgfault_upcall = func;
	return 0;
}
~~~

#### excited

* 用户异常栈： 用户自定义的handler函数所使用的栈，在UXSTACKTOP下的一个PGSIZE。
* handle的流程：
	* PGFLT时进入到kernel中，kernel会路由，随后：
		* 如果upcall不存在，那么简单的销毁这个进程（如同Lab3）
		* 如果存在，那么就跳转到用户设置好的upcall中去，在用户异常栈上保存好当前trap-time的寄存器，**并且不再返回**
	* 进入到用户设置好的upcall中（使用的是用户异常栈），执行，其作用是
		* 调用真正的handler
		* 处理完毕后，通过用户异常栈上保存好的UTF返回到trap-time stack中，进而返回到user env中

### Exercise 8

实现page_fault_handler.

~~~c
	if (curenv->env_pgfault_upcall != NULL){
		struct UTrapframe *utf = NULL;
		if (UXSTACKTOP - PGSIZE <= tf->tf_esp && tf->tf_esp < UXSTACKTOP)
			utf = (struct UTrapframe *)(tf->tf_esp - 4 - sizeof(struct UTrapframe));
		else if (USTACKTOP - PGSIZE <= tf->tf_esp && tf->tf_esp < USTACKTOP)
			utf = (struct UTrapframe *)(UXSTACKTOP - sizeof(struct UTrapframe));
		
		user_mem_assert(curenv, utf, sizeof(utf), PTE_W | PTE_U | PTE_P);
		utf->utf_fault_va = fault_va;
		utf->utf_err = tf->tf_err;
		utf->utf_regs = tf->tf_regs;
		utf->utf_eip = tf->tf_eip;
		utf->utf_eflags = tf->tf_eflags;
		utf->utf_esp = tf->tf_esp;
		tf->tf_esp = (uintptr_t) utf;
		tf->tf_eip = (uintptr_t) curenv->env_pgfault_upcall;
		env_run(curenv);
	}

	// Destroy the environment that caused the fault.
	cprintf("[%08x] user fault va %08x ip %08x\n",
		curenv->env_id, fault_va, tf->tf_eip);
	print_trapframe(tf);
	env_destroy(curenv);
~~~

首先判断是否有设置过upcall，没有就销毁。如果有的话：
* 如果env执行在用户栈上，那么在UXSTACKTOP上插入UTrapframe
* 如果env执行在用户异常栈上（用户可能handle套handle），那么先push一个4B的空位再插入utf。

现在用户异常栈上已经被压好一个UTF了，一个UTrapframe的数据结构如下：

~~~c
struct UTrapframe {
	/* information about the fault */
	uint32_t utf_fault_va;  /* va for T_PGFLT, 0 otherwise */
	uint32_t utf_err;
	/* trap-time return state */
	struct PushRegs utf_regs;
	uintptr_t utf_eip;
	uint32_t utf_eflags;
	/* the trap-time stack to return to */
	uintptr_t utf_esp;
} __attribute__((packed));
~~~

### Exercise 9

完成_pgfault_upcall，这个是真正注册的upcall，其作用在excited中有所提及。先看JOS
提供的部分：

~~~Nasm
_pgfault_upcall:
	// Call the C page fault handler.
	pushl %esp			// function argument: pointer to UTF
	movl _pgfault_handler, %eax
	call *%eax
	addl $4, %esp			// pop function argument
~~~

逐行来看，pushl %esp是最关键的，esp是指向utf的，并且通过addl跳过了函数参数，这个时候，stack如下所示：

~~~
	// exception stack:
	//
	//	trap-time esp
	//	trap-time eflags
	//	trap-time eip			<-- address we need to store
	//	utf_regs.reg_eax		<-- 32B, 8regs
	//	...
	//	utf_regs.reg_esi
	//	utf_regs.reg_edi
	//	utf_err (error code)
	//	utf_fault_va            <-- current esp!
~~~

而程序的目标是让trap-time esp（trap-time stack上的，而不是用户异常栈，虽然在物理内存上看可能差不多在一起）指向trap-time eip，好使得其通过popl %esp，ret的方法回到user env。如下是我们希望最后栈（trap-time stack）的样子，并且eflags、trap-time regs和trap-time esp都得到恢复：

~~~
  //  +----trap-time-stack------+
  //  |            ...          |
  //  +-------------------------+
  //  |   trap-time-eip    (4B) |
  //  +-------------------------+   <-- trap_time_esp
~~~

~~~Nasm
	# 将trap-time esp减4，用来放trap-time eip
	# 我们的目的是把trap-time eip偷偷压到trap-time stack上
	movl 0x30(%esp), %eax
	subl $0x4, %eax
	movl %eax, 0x30(%esp)

	# 把trap-time eip放到上一步留出的位置上
	movl 0x28(%esp), %ebx
	movl %ebx, (%eax)
	
	# 恢复所有的trap-time registers
	addl $0x8, %esp
	popal

	# 恢复eflags
	addl $0x4, %esp
	popfl

	# 跳回到trap-time stack上
	pop %esp
	ret
~~~

#### Exercise 10

实现set_pgfault_handler的包装。

~~~c
void
set_pgfault_handler(void (*handler)(struct UTrapframe *utf))
{
	int r;

	if (_pgfault_handler == 0) {
		// First time through!
		// LAB 4: Your code here.
		if((r = sys_page_alloc(0,(void*)(UXSTACKTOP-PGSIZE),PTE_U|PTE_P|PTE_W)) < 0)
			panic("set_pgfault_handler: %e\n", r);
		sys_env_set_pgfault_upcall(0, _pgfault_upcall);
	}

	// Save handler pointer for assembly to call.
	_pgfault_handler = handler;
}
~~~

完成到这里之后，可以通过partB除了forktree以外所有的test。

### Challenge!

实现其余trap的用户自定义handler。这个challenge看上去比较好实现，过程和partB几乎没有什么区别。我在env中新设置了三种handler，然后按照类似的步骤写好注册函数/包装函数，又写了三个user程序用来分别检测divzero/gpfault/illoc三种异常。助教如果想检测我的完成情况，要先在inc/challenge.h中取消#define LAB4_CHALLENGE4的注释。

随后分别运行：`make run-dividebyzero`,`make run-gpfault`,`make-run-illoc`，可以看到正确的输出。	

### Exercise 11

#### excited

在初始化时，JOS做了一些处理，使得UVPT这个虚拟地址指向env_pgdir和kern_pgdir：

~~~c
//init.c/mem_init()
kern_pgdir[PDX(UVPT)] = PADDR(kern_pgdir) | PTE_U | PTE_P;

//env.c/env_setup_vm()
e->env_pgdir[PDX(UVPT)] = PADDR(e->env_pgdir) | PTE_P | PTE_U;
~~~

同时又在entry.S中定义了：

~~~Nasm
.data
// Define the global symbols 'envs', 'pages', 'vpt', and 'vpd'
// so that they can be used in C as if they were ordinary global arrays.
	.globl envs
	.set envs, UENVS
	.globl pages
	.set pages, UPAGES
	.globl vpt
	.set vpt, UVPT
	.globl vpd
	.set vpd, (UVPT+(UVPT>>12)*4)
~~~

* vpt[N]：存放PGNUM(va)为N的PTE
* vpd[PDX(va)]：va对应的pde的内容

#### exercise

实现COW的fork，用类似dumbfork中的做法，把需要复制的页用duppage复制过去。

##### duppage

通过vpt和vpd检查权限是否正确，随后进行page_map.

~~~c
	int r;
	void *va = (void *) (pn * PGSIZE);
	if(!(vpd[PDX(va)] & PTE_P))
		return -1;
	if(!(vpt[pn] & (PTE_W | PTE_COW)))
		return -1;
	if((r = sys_page_map(0, va, envid, va, PTE_U | PTE_COW | PTE_P) < 0))
		return -1;
	if((r = sys_page_map(0, va, 0, va, PTE_U | PTE_COW | PTE_P) < 0))
		return -1;

	return 0;
~~~

##### pgfault

本地的PGFLT处理者（真正干活的），其处理发生COW的页，将一个page从parent拷贝到son。实际过程和dumbfork的duppage比较类似，代码就不贴了：

* 为son分配新page
* parent把TEMP段复制到va所映射的空间
* parent把son的新page映射到同一空间
* parent取消自己对这一空间的map

##### fork

仅展示其中一部分，fork需要把pgfault通过系统调用设置好，通过sys_exofork()获得一个新env，随后：

* 因为有一部分env的数据结构在sys_exofork中设置好了，还剩下用户异常栈与pgfault_upcall：
	* 分配一个页给子进程的用户异常栈，并设置好权限
	* 设置pgfault_upcall， 然后设置env为RUNNABLE
* 对子进程的page_table做初始化
	* duppage(UTEXT, USTACKTOP)

~~~c
	if ((r = sys_page_alloc(envid, (void *) (UXSTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W)) < 0)
		return r;

	// Map the pages according to flags in PTE
	for (addr = 0; addr < UXSTACKTOP - PGSIZE; addr += PGSIZE) {
		if (!(vpd[PDX(addr)] & PTE_P)) {
			addr += PGSIZE * (NPTENTRIES - 1);
			continue;
		}
		if (!(vpt[PGNUM(addr)] & PTE_P))
			continue;
		if ((r = duppage(envid, PGNUM(addr))) < 0)
			return r;
	}

	if ((r = sys_env_set_pgfault_upcall(envid, _pgfault_upcall)) < 0)
		return r;
	if ((r = sys_env_set_status(envid, ENV_RUNNABLE)) < 0)
		return r;
	return envid;
~~~

#### excited

在正确完成以上工作后，我运行make run-forktree并且输出trapframe的err信息，得到了“out of memory”的结果，对这一错误我也茫然了很长一段时间。最终，我检查报错的地点，查看了大部分会返回E_NO_MEM的函数。发现lab2中，我实现的page_insert缺少了一步tlb_invalidate，可能是因为forktree创建的子进程比较多，我没有fresh tlb的行为才导致了env的用尽（但我觉得也就十多个进程也不太可能）。总之，解决了这个问题。

partB完成，收获55/55.

### Part C：Preemptive Multitasking and Inter-Process communication

PartC需要实现时钟中断、抢占式调度和IPC。

### Exercise 12

在PartA时，我已经被迫写好了时钟中断的SETGATE，就用相同的方式设置好IRQ1-IRQ15，时钟中断是IRQ0，对应IDT中的32-47。

在boot的时候和sysenter构建Trapframe时通过eflags的IF位开启外部中断，因为JOS是通过外部中断的方式来实现抢占式调度的。sti指令也是为了打开sysenter所关闭的外部中断。

* 因为Trapframe的eflags中记录了IF位为1，所以在通过TF恢复eflags并恢复到用户态的时候，就自然的允许了外部中断。

~~~c
e->env_tf.tf_eflags = e->env_tf.tf_eflags | FL_IF;
~~~

### Exercise 13

在PartA中我已经阐述过kernel产生时钟中断的方法，其通过lapic_init和pic_init设置启用了该方法。在trap_dispatch里，我需要让内核在收到trap后调度到其他进程：

~~~c
	if (tf->tf_trapno == IRQ_OFFSET + IRQ_TIMER) {
		lapic_eoi();
		sched_yield();
		return;
	}
~~~

### Exercise 14

最后一个exercise！在这里要实现JOS的IPC，包括两个系统调用：sys_ipc_recv和sys_ipc_try_send，以及两个lib的包装：ipc_recv和ipc_send。

其中sys_ipc_try_send是不阻塞的，它尝试向指定的envid发送value（以及可能的page），如果envid不在sys_ipc_recv的过程中，那么就直接返回E_IPC_NOT_RECV。而sys_ipc_recv是阻塞的，他通过一个sched_yield()让kernel调度别的进程，直到sender给他发送value和可能的Page后，将其设置为RUNNABLE，才能继续下去。

#### Env的数据结构

JOS为我更新了Env的数据结构，通过这些可以实现上文所述的IPC：

~~~c
bool env_ipc_recving;	// false表明这个env拒绝接受任何消息
void *env_ipc_dstva;	// page mapping部分，IPC还可以传递一个Page的映射
uint32_t env_ipc_value;	// 传递的32bit的消息
envid_t env_ipc_from;	// sender的信息
int env_ipc_perm;		// page mapping的权限
~~~

#### sys_ipc_recv

阻塞的sys_ipc_recv，可以看到置其为NOT_RUNNABLE的代码和yield。在这里也可以看出JOS的IPC并不安全，因为任何进程都可以给任何进程发送消息，这里没有对sender是谁的检查。

~~~c
static int
sys_ipc_recv(void *dstva)
{
	if ( PGOFF(dstva) != 0 && dstva < (void*)UTOP )
		return -E_INVAL;
	curenv->env_status = ENV_NOT_RUNNABLE;
	curenv->env_ipc_dstva = dstva;
	curenv->env_ipc_from = 0;
	curenv->env_ipc_recving = 1;
	sched_yield();
	return 0;
}
~~~

#### sys_ipc_try_send

~~~c
static int
sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm)
{
	int r;
	struct Env * dstenv;
	pte_t * pte;
	struct Page *pp;

	//	-E_BAD_ENV if environment envid doesn't currently exist.
	//		(No need to check permissions.)
	r = envid2env(envid, &dstenv, 0);
	if (r < 0)
		return -E_BAD_ENV;
	//	-E_IPC_NOT_RECV if envid is not currently blocked in sys_ipc_recv,
	//		or another environment managed to send first.
	if (!dstenv->env_ipc_recving || dstenv->env_ipc_from != 0)
		return -E_IPC_NOT_RECV;

	if (srcva < (void*)UTOP){
		//	-E_INVAL if srcva < UTOP but srcva is not page-aligned.
		if(PGOFF(srcva) != 0) return -E_INVAL;

		//	-E_INVAL if srcva < UTOP and perm is inappropriate
		if ((perm & (PTE_U | PTE_P)) != (PTE_U | PTE_P))
			return -E_INVAL;
		if ((perm | PTE_SYSCALL) != PTE_SYSCALL)
			return -E_INVAL;

		//	-E_INVAL if srcva < UTOP but physical page not exist
		pp = page_lookup(curenv->env_pgdir, srcva, &pte);
		if (!pp) return -E_INVAL;

		//	-E_INVAL if (perm & PTE_W), but write conflict
		if ((perm & PTE_W) && !(*pte & PTE_W))
			return -E_INVAL;

		//send mapping
		if (dstenv->env_ipc_dstva){
			//actually DO map
			r = page_insert(dstenv->env_pgdir, pp, dstenv->env_ipc_dstva, perm);
			if (r < 0)
				return -E_NO_MEM;
		}

	}
	dstenv->env_ipc_perm = perm;
	dstenv->env_ipc_recving = 0;
	dstenv->env_ipc_value = value;
	dstenv->env_ipc_from = curenv->env_id;
	dstenv->env_status = ENV_RUNNABLE;
	
	//important
	dstenv->env_tf.tf_regs.reg_eax = 0;
	return 0;
}
~~~

#### lib的包装

* recv中通过传递一个UTOP表示不传递page。
* send反复尝试，直到成功send为止。
	* 它只接受IPC_NOT_RECV这一种错误
	* 使用sys_yield来变得CPU友好

~~~c
int32_t
ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)
{
	int r;
	if (pg == NULL)
		r = sys_ipc_recv((void *) UTOP);
	else
		r = sys_ipc_recv(pg);
	
	if (r < 0) {
		if (from_env_store)
			*from_env_store = 0;
		if (perm_store)
			*perm_store = 0;
		return r;
	}

	if (from_env_store)
		*from_env_store = thisenv->env_ipc_from;
	if (perm_store)
		*perm_store = thisenv->env_ipc_perm;
	return thisenv->env_ipc_value;
}


void
ipc_send(envid_t to_env, uint32_t val, void *pg, int perm)
{
	int r = -E_IPC_NOT_RECV;
	while(r < 0){
		if (r != -E_IPC_NOT_RECV)
			panic("ipc_send: %e\n", r);
		if (pg)
			r = sys_ipc_try_send(to_env, val, pg, perm);
		else
			r = sys_ipc_try_send(to_env, val, (void*)UTOP, perm);
	}
	sys_yield();
}
~~~

#### excited

到这个部分之后，按照文档所述，应该可以通过全部测试(75/75)，但是当我运行make run-primes时，却发现有时会因为超时而错。对于这个问题，我尝试了去优化sched_yield，让它少做一些if判断，可惜没有太大的用处。分析下来觉得可能是由于try_send的系统调用不阻塞，阻塞发生在用户态的send中，这样反复的从kernel到user的切换影响了速度。我没有优化这一点，但我希望文档阅读者能够明白我的IPC实现是正确的，运行primes的输出是合意的。